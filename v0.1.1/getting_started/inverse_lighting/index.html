<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Inverse Lighting · RayTracer</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link href="../../assets/documenter.css" rel="stylesheet" type="text/css"/><link href="../../assets/raytracer.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>RayTracer</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../../">Home</a></li><li><span class="toctext">Getting Started</span><ul><li><a class="toctext" href="../teapot_rendering/">Introduction to Rendering</a></li><li class="current"><a class="toctext" href>Inverse Lighting</a><ul class="internal"><li><a class="toctext" href="#Configuring-the-Scene-1">Configuring the Scene</a></li><li><a class="toctext" href="#inv_light-1">Ground Truth Image</a></li><li><a class="toctext" href="#Initial-Guess-of-Lighting-Parameters-1">Initial Guess of Lighting Parameters</a></li><li><a class="toctext" href="#Optimization-Loop-1">Optimization Loop</a></li></ul></li><li><a class="toctext" href="../optim_compatibility/">Optimizing using Optim.jl</a></li></ul></li><li><span class="toctext">API Documentation</span><ul><li><a class="toctext" href="../../api/utilities/">General Utilities</a></li><li><a class="toctext" href="../../api/differentiation/">Differentiation</a></li><li><a class="toctext" href="../../api/scene/">Scene Configuration</a></li><li><a class="toctext" href="../../api/renderers/">Renderers</a></li><li><a class="toctext" href="../../api/optimization/">Optimization</a></li><li><a class="toctext" href="../../api/accelerators/">Acceleration Structures</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Getting Started</li><li><a href>Inverse Lighting</a></li></ul><a class="edit-page" href="https://github.com/avik-pal/RayTracer.jl/blob/master/docs/src/getting_started/inverse_lighting.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Inverse Lighting</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Inverse-Lighting-Tutorial-1" href="#Inverse-Lighting-Tutorial-1">Inverse Lighting Tutorial</a></h1><p>In this tutorial we shall explore the inverse lighting problem. Here, we shall try to reconstruct a target image by optimizing the parameters of the light source (using gradients).</p><pre><code class="language-julia">using RayTracer, Images, Zygote, Flux, Statistics</code></pre><h2><a class="nav-anchor" id="Configuring-the-Scene-1" href="#Configuring-the-Scene-1">Configuring the Scene</a></h2><p>Reduce the screen_size if the optimization is taking a bit long</p><pre><code class="language-julia">screen_size = (w = 300, h = 300)</code></pre><p>Now we shall load the scene using <a href="../../api/scene/#RayTracer.load_obj-Tuple{Any}"><code>load_obj</code></a> function. For this we need the <a href="https://en.wikipedia.org/wiki/Wavefront_.obj_file"><code>obj</code></a> and <a href="https://en.wikipedia.org/wiki/Wavefront_.obj_file#Material_template_library"><code>mtl</code></a> files. They can be downloaded using the following commands:</p><pre><code class="language-none">wget https://raw.githubusercontent.com/tejank10/Duckietown.jl/master/src/meshes/tree.obj
wget https://raw.githubusercontent.com/tejank10/Duckietown.jl/master/src/meshes/tree.mtl</code></pre><pre><code class="language-julia">scene = load_obj(&quot;./tree.obj&quot;)</code></pre><p>Let us set up the <a href="../../api/scene/#RayTracer.Camera"><code>Camera</code></a>. For a more detailed understanding of the rendering process look into <a href="../teapot_rendering/#Introduction-to-rendering-using-RayTracer.jl-1">Introduction to rendering using RayTracer.jl</a>.</p><pre><code class="language-julia">cam = Camera(
    lookfrom = Vec3(0.0f0, 6.0f0, -10.0f0),
    lookat   = Vec3(0.0f0, 2.0f0,  0.0f0),
    vup      = Vec3(0.0f0, 1.0f0,  0.0f0),
    vfov     = 45.0f0,
    focus    = 0.5f0,
    width    = screen_size.w,
    height   = screen_size.h
)

origin, direction = get_primary_rays(cam)</code></pre><p>We should define a few convenience functions. Since we are going to calculate the gradients only wrt to <code>light</code> we have it as an argument to the function. Having <code>scene</code> as an additional parameters simply allows us to test our method for other meshes without having to run <code>Zygote.refresh()</code> repeatedly.</p><pre><code class="language-julia">function render(light, scene)
    packed_image = raytrace(origin, direction, scene, light, origin, 2)
    array_image = reshape(hcat(packed_image.x, packed_image.y, packed_image.z),
                          (screen_size.w, screen_size.h, 3, 1))
    return array_image
end

showimg(img) = colorview(RGB, permutedims(img[:,:,:,1], (3,2,1)))</code></pre><h2><a class="nav-anchor" id="inv_light-1" href="#inv_light-1">Ground Truth Image</a></h2><p>For this tutorial we shall use the <a href="../../api/scene/#RayTracer.PointLight"><code>PointLight</code></a> source. We define the ground truth lighting source and the rendered image. We will later assume that we have no information about this lighting condition and try to reconstruct the image.</p><pre><code class="language-julia">light_gt = PointLight(
    color     = Vec3(1.0f0, 1.0f0, 1.0f0),
    intensity = 20000.0f0,
    position  = Vec3(1.0f0, 10.0f0, -50.0f0)
)

target_img = render(light_gt, scene)</code></pre><p>The presence of <a href="../../api/utilities/#RayTracer.zeroonenorm-Tuple{Any}"><code>zeroonenorm</code></a> is very important here. It rescales the values in the image to 0 to 1. If we don&#39;t perform this step <code>Images</code> will clamp the values while generating the image in RGB format.</p><pre><code class="language-julia">showimg(zeroonenorm(target_img))</code></pre><p align="center">
    <img width=300 height=300 src="../../assets/inv_light_original.png">
</p><h2><a class="nav-anchor" id="Initial-Guess-of-Lighting-Parameters-1" href="#Initial-Guess-of-Lighting-Parameters-1">Initial Guess of Lighting Parameters</a></h2><p>We shall make some arbitrary guess of the lighting parameters (intensity and position) and try to get back the image in <a href="#inv_light-1">Ground Truth Image</a></p><pre><code class="language-julia">light_guess = PointLight(
    color     = Vec3(1.0f0, 1.0f0, 1.0f0),
    intensity = 1.0f0,
    position  = Vec3(-1.0f0, -10.0f0, -50.0f0)
)

showimg(zeroonenorm(render(light_guess, scene)))</code></pre><p align="center">
    <img width=300 height=300 src="../../assets/inv_light_initial.png">
</p><p>We shall store the images in <code>results_inv_lighting</code> directory</p><pre><code class="language-julia">mkpath(&quot;results_inv_lighting&quot;)

save(&quot;./results_inv_lighting/inv_light_original.png&quot;,
     showimg(zeroonenorm(render(light_gt, scene))))
save(&quot;./results_inv_lighting/inv_light_initial.png&quot;,
     showimg(zeroonenorm(render(light_guess, scene))))</code></pre><h2><a class="nav-anchor" id="Optimization-Loop-1" href="#Optimization-Loop-1">Optimization Loop</a></h2><p>We will use the ADAM optimizer from Flux. (Try experimenting with other optimizers as well). We can also use frameworks like Optim.jl for optimization. We will show how to do it in a future tutorial</p><pre><code class="language-julia">for i in 1:401
    loss, back_fn = Zygote.forward(light_guess) do L
        sum((render(L, scene) .- target_img) .^ 2)
    end
    @show loss
    gs = back_fn(1.0f0)
    update!(opt, light_guess.intensity, gs[1].intensity)
    update!(opt, light_guess.position, gs[1].position)
    if i % 5 == 1
        save(&quot;./results_inv_lighting/iteration_$i.png&quot;,
             showimg(zeroonenorm(render(light_guess, scene))))
    end
end</code></pre><p>If we generate a <code>gif</code> for the optimization process it will look similar to this</p><p align="center">
     <img width=300 height=300 src="../../assets/inv_lighting.gif">
</p><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p><footer><hr/><a class="previous" href="../teapot_rendering/"><span class="direction">Previous</span><span class="title">Introduction to Rendering</span></a><a class="next" href="../optim_compatibility/"><span class="direction">Next</span><span class="title">Optimizing using Optim.jl</span></a></footer></article></body></html>
